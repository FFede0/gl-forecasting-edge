{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras import metrics\n",
    "\n",
    "from gossiplearning.config import Config\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:05:26.702606Z",
     "start_time": "2023-10-04T11:05:26.681061Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from utils.metrics import SimulationMetrics, plot_metrics, average_metrics, plot_metrics_boxplot, \\\n",
    "    dump_experiment_metrics\n",
    "from pathlib import Path\n",
    "from utils.evaluation import evaluate_simulations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:05:26.754683Z",
     "start_time": "2023-10-04T11:05:26.749009Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:05:26.934087Z",
     "start_time": "2023-10-04T11:05:26.928783Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = Config.model_validate(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dataset_base_dir = Path(\"data/datasets/1func_10nodes_3k\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:05:27.099971Z",
     "start_time": "2023-10-04T11:05:27.096235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Metal device set to: Apple M1 Pro\n",
      "Metal device set to: Apple M1 Pro\n",
      "Metal device set to: Apple M1 Pro\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n"
     ]
    }
   ],
   "source": [
    "simulations_metrics, simulations_generalization_metrics = evaluate_simulations(5, config,  dataset_base_dir, evaluate_generalization=True) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:13:28.466124Z",
     "start_time": "2023-10-04T11:05:27.518171Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "averaged_metrics = SimulationMetrics(\n",
    "    gossip=average_metrics([m.gossip for m in simulations_metrics]),\n",
    "    single_training=average_metrics([m.single_training for m in simulations_metrics]),\n",
    "    centralized=average_metrics([m.centralized for m in simulations_metrics]),\n",
    ")\n",
    "\n",
    "averaged_generalization_metrics = SimulationMetrics(\n",
    "    gossip=average_metrics([m.gossip for m in simulations_generalization_metrics]),\n",
    "    single_training=average_metrics([m.single_training for m in simulations_generalization_metrics]),\n",
    "    centralized=average_metrics([m.centralized for m in simulations_generalization_metrics]),\n",
    ")\n",
    "\n",
    "aggregated_plots = Path(config.workspace_dir) / \"plots\"\n",
    "aggregated_plots.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "plot_metrics(averaged_metrics, aggregated_plots / \"metrics_hist.png\")\n",
    "plot_metrics(averaged_generalization_metrics, aggregated_plots / \"generalized_metrics_hist.png\")\n",
    "\n",
    "plot_metrics_boxplot(simulations_metrics, aggregated_plots / \"metrics_boxplot.png\")\n",
    "plot_metrics_boxplot(simulations_generalization_metrics, aggregated_plots / \"generalized_metrics_boxplot.png\")\n",
    "\n",
    "dump_experiment_metrics(averaged_metrics, Path(config.workspace_dir) / \"metrics.csv\")\n",
    "dump_experiment_metrics(averaged_generalization_metrics, Path(config.workspace_dir) / \"metrics_generalized.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:13:40.893373Z",
     "start_time": "2023-10-04T11:13:28.477460Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test and prototyping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = np.load(\"data/datasets/1func_10nodes_3k/0/4in/node_0.npz\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T16:29:27.811165Z",
     "start_time": "2023-09-26T16:29:27.805857Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_test, Y_test = dataset[\"X_test\"], dataset[\"Y_test\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T16:29:27.976094Z",
     "start_time": "2023-09-26T16:29:27.971304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"experiments/1fn_10n3k_0/0/models/0.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T16:29:28.608116Z",
     "start_time": "2023-09-26T16:29:28.154185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T16:29:31.182480Z",
     "start_time": "2023-09-26T16:29:29.234024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(10452, 1)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T16:29:31.863221Z",
     "start_time": "2023-09-26T16:29:31.845751Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from utils.metrics import Metrics\n",
    "\n",
    "\n",
    "def compute_metrics(truth: Union[np.ndarray, list[np.ndarray]], predicted: np.ndarray) -> Metrics:\n",
    "    flattened_truth = truth.flatten()\n",
    "    flattened_pred = predicted.flatten()\n",
    "\n",
    "    return Metrics(\n",
    "        mse=metrics.mean_squared_error(flattened_truth, flattened_pred),\n",
    "        rmse=math.sqrt(metrics.mean_squared_error(flattened_truth, flattened_pred)),\n",
    "        msle=metrics.mean_squared_log_error(flattened_truth, flattened_pred),\n",
    "        mae=metrics.mean_absolute_error(flattened_truth, flattened_pred),\n",
    "        mape=metrics.mean_absolute_percentage_error(flattened_truth, flattened_pred),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-16T11:06:46.048969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m flattened_pred \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(\u001B[43mp\u001B[49m)\n\u001B[1;32m      3\u001B[0m flattened_pred\n",
      "\u001B[0;31mNameError\u001B[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "flattened_pred = np.concatenate(p)\n",
    "flattened_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T16:29:05.100527Z",
     "start_time": "2023-09-26T16:29:04.817798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m n_elements \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39mprod(\u001B[43mY_test\u001B[49m\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# x = Y_test.reshape((15456, ), order=\"F\")\u001B[39;00m\n\u001B[1;32m      6\u001B[0m n_elements\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "n_elements = math.prod(Y_test.shape)\n",
    "\n",
    "# x = Y_test.reshape((15456, ), order=\"F\")\n",
    "n_elements"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T16:29:05.528220Z",
     "start_time": "2023-09-26T16:29:05.519411Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gossiplearning import History\n",
    "\n",
    "history = History.model_validate(\n",
    "        json.load((Path(\"experiments/3fn_10n3k_0/0\") / \"history.json\").open(\"r\"))\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-16T11:06:46.051646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history.nodes_training_history[0].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-16T11:06:46.052716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-16T11:06:46.053571Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.evaluation import plot_node_history\n",
    "\n",
    "plot_node_history(history.nodes_training_history[0], \"test.png\", fn_name=\"fn_0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-16T11:06:46.054635Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
