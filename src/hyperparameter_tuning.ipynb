{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T06:49:17.136437Z",
     "start_time": "2023-07-10T06:49:17.133355Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "from keras import Sequential, Input\n",
    "import keras_tuner\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from keras.src.optimizers import Adam\n",
    "\n",
    "from utils.centralized_training import _build_centralized_model_dataset\n",
    "from gossiplearning.config import Config\n",
    "from keras.src.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T06:49:17.139810Z",
     "start_time": "2023-07-10T06:49:17.136871Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"azurefunctions_config.json\", \"r\") as f:\n",
    "  config = Config.model_validate(json.load(f))\n",
    "\n",
    "INPUT_SHAPE = (\n",
    "  config.training.input_timesteps, config.training.n_input_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T06:49:17.145162Z",
     "start_time": "2023-07-10T06:49:17.143319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_builder(hp: keras_tuner.HyperParameters) -> keras.Model:\n",
    "    model = Sequential()\n",
    "    # LSTM layer\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            hp.Int(\n",
    "                min_value=16, max_value=320, step=16, name=\"lstm_layer_1_dim\"\n",
    "            ),\n",
    "            activation=\"tanh\",\n",
    "            input_shape=INPUT_SHAPE,\n",
    "            return_sequences=True,\n",
    "        )\n",
    "    )\n",
    "    # dropout\n",
    "    if hp.Boolean(\"dropout_1\"):\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                hp.Float(\n",
    "                    name=\"dropout_1_rate\", \n",
    "                    min_value=0.1, \n",
    "                    max_value=0.5, \n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    # LSTM layer\n",
    "    if hp.Boolean(\"lstm_2\"):\n",
    "        # model.add(RepeatVector(1)),\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                hp.Int(\n",
    "                    min_value=16, \n",
    "                    max_value=320, \n",
    "                    step=16, \n",
    "                    name=\"lstm_layer_2_dim\"\n",
    "                ),\n",
    "                activation=\"tanh\",\n",
    "                input_shape=(4, 14),\n",
    "                # return_sequences=True,\n",
    "            )\n",
    "        )\n",
    "    # dropout\n",
    "    if hp.Boolean(\"dropout_2\"):\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                hp.Float(\n",
    "                    name=\"dropout_2_rate\", \n",
    "                    min_value=0.1, \n",
    "                    max_value=0.5, \n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    # Dense layer\n",
    "    if hp.Boolean(\"dense\"):\n",
    "        model.add(\n",
    "            Dense(\n",
    "                hp.Int(min_value=16, max_value=320, step=16, name=\"dense_dim\"),\n",
    "                activation=\"relu\"\n",
    "            )\n",
    "        )\n",
    "    # output layer\n",
    "    model.add(\n",
    "        Dense(1, activation='relu')\n",
    "    )\n",
    "    # optimizer\n",
    "    optz = Adam(\n",
    "        learning_rate=hp.Float(\n",
    "            min_value=0.0005, max_value=0.01, step=0.0005, name=\"learning_rate\"\n",
    "        )\n",
    "    )\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        optimizer=optz, \n",
    "        loss='mape', \n",
    "        metrics=[\"mae\", \"msle\", \"mse\", \"mape\", RootMeanSquaredError()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T06:49:17.467810Z",
     "start_time": "2023-07-10T06:49:17.146411Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=30,\n",
    "    directory=\"../experiments\",\n",
    "    project_name=\"hyperparameter_tuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T06:49:17.501557Z",
     "start_time": "2023-07-10T06:49:17.469324Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train, val, _ = _build_centralized_model_dataset(Path(\"data/datasets/4func_10nodes/0\"), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurefunctions_utils import load_dataset\n",
    "\n",
    "train, val, _ = load_dataset(\n",
    "  \"../experiments/azurefunctions-dataset2019/10n_k3_15min/seed4850/0\", \n",
    "  \"centralized\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 15s]\n",
      "val_loss: 74.92354583740234\n",
      "\n",
      "Best val_loss So Far: 74.92232513427734\n",
      "Total elapsed time: 00h 06m 23s\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=config.training.patience,\n",
    "    min_delta=config.training.min_delta,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train[0], \n",
    "    train[1], \n",
    "    validation_data=val, \n",
    "    callbacks=[early_stopping], \n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T08:31:11.477978Z",
     "start_time": "2023-07-10T08:31:11.475266Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../experiments/hyperparameter_tuning\n",
      "Showing 1 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "lstm_layer_1_dim: 176\n",
      "dropout_1: False\n",
      "lstm_2: True\n",
      "dropout_2: True\n",
      "dense: False\n",
      "learning_rate: 0.0055\n",
      "lstm_layer_2_dim: 48\n",
      "dense_dim: 48\n",
      "dropout_2_rate: 0.35\n",
      "Score: 74.92232513427734\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary(num_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T08:31:11.480357Z",
     "start_time": "2023-07-10T08:31:11.478407Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11.11_gldfaas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
